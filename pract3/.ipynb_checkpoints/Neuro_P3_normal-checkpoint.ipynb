{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -U keras-tuner\n",
    "# !pip3 install tensorflow\n",
    "# !pip3 install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1651675192634,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "oY36uRqOavkU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1651675193336,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "nH2J34Gfbv_C"
   },
   "outputs": [],
   "source": [
    "dataset_url = 'https://www.openml.org/data/get_csv/4965303/flare.arff' \n",
    "dataset = np.genfromtxt(dataset_url, delimiter=',', skip_header=1)\n",
    "\n",
    "x = dataset[:,:-4]\n",
    "x_size = x.shape[1]\n",
    "y = dataset[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1651674881815,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "B_ubQqvR99Z5",
    "outputId": "fc5776ce-e8da-4820-c0da-8e00fa6508e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1066, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKjVzq5PFAa5"
   },
   "source": [
    "### <font color=\"#CA3532\">Definición del modelo</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1651675197890,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "jSiN2kBpfJH2"
   },
   "outputs": [],
   "source": [
    "# Definid el modelo con Keras\n",
    "\n",
    "nn = Sequential()\n",
    "\n",
    "### -------------------------------------------------------------------------------\n",
    "### Añadir la capas completamente conectadas que consideréis al modelo\n",
    "### -------------------------------------------------------------------------------\n",
    "nn.add(Dense(12, activation=\"sigmoid\"))\n",
    "nn.add(Dense(12, activation=\"sigmoid\"))\n",
    "nn.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1651675198759,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "tU7t0cyMf-pL"
   },
   "outputs": [],
   "source": [
    "metrics = [\n",
    "            keras.metrics.BinaryAccuracy(name='ACC'),\n",
    "            keras.metrics.Precision(name='Prec'),\n",
    "            keras.metrics.Recall(name='Rec'),\n",
    "            keras.metrics.AUC(name='AUC'),\n",
    "          ]\n",
    "\n",
    "nn.compile(optimizer='SGD', loss=\"mse\", metrics=metrics)\n",
    "# nn.compile(optimizer='Adam', loss=\"binary_crossentropy\", metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dRac4W1t69B"
   },
   "source": [
    "### <font color=\"#CA3532\">Conjuntos de entrenamiento y validación</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1651675195719,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "QA3AW4y7j_Ar"
   },
   "outputs": [],
   "source": [
    "# Contrucción de los conjuntos de entrenamiento y validación\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, stratify=y, test_size=0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDFUBCUVugVj"
   },
   "source": [
    "### <font color=\"#CA3532\">Visualización de resultados</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1651674881817,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "6pgKzRcysRwv"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def show_metrics(history):\n",
    "    for metric in history.history.keys():\n",
    "        if not metric.startswith('val_'):\n",
    "            plt.plot(history.history[metric], label=metric)\n",
    "            plt.plot(history.history[f'val_{metric}'], label=f'val_{metric}')\n",
    "            plt.title(metric)\n",
    "            plt.ylabel('')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(loc=\"upper left\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zo8KQlCaGEw9"
   },
   "source": [
    "### <font color=\"#CA3532\">Entrenamiento de la red neuronal y evaluación</font>\n",
    "Como podrás haber observado en problema no está balanceado (o está bastante desequilibrado), porque el número de ejemplos de cada clase es muy diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1651675202625,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "5BGYvZXUivZb"
   },
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEK6W2Q3B8yv"
   },
   "source": [
    "#### RandomUnderSampler\n",
    "Debido a al desequilibrio entre clases se aplica un random under sampler a partir de lo cual el numero de registros de cada clase se equilibra quitandose registros aleatorios de la clase mayoritaria quedando ambas clases con 145 registros. Debido a este equilibrio de clases se obtienen f1 scores equilibrados en entrenamiento para ambas clases ya que el modelo no pondera una clase debido a la equidad de registros de una clase respecto a la otra. Sin embargo en test generaliza peor para la clase 1, debido a que le faltan mas registros para el entrenamiento de esta clase para generalizar bien o quizas debido a sobre ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1651674881818,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "Bxm0VENEjiO1",
    "outputId": "6fb1f094-2bb8-4f0a-961b-98a1a82718d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 145, 1.0: 145})\n"
     ]
    }
   ],
   "source": [
    "undersample = RandomUnderSampler()\n",
    "X_under_train, y_under_train = undersample.fit_resample(x_train, y_train)\n",
    "print(Counter(y_under_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9016,
     "status": "ok",
     "timestamp": 1651674890827,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "5V5-pLhikC2R",
    "outputId": "e6844c1d-0baf-48ce-cc4e-88c88cf0281b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.79      0.72       145\n",
      "         1.0       0.74      0.61      0.67       145\n",
      "\n",
      "    accuracy                           0.70       290\n",
      "   macro avg       0.70      0.70      0.69       290\n",
      "weighted avg       0.70      0.70      0.69       290\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.65      0.75       177\n",
      "         1.0       0.28      0.65      0.39        37\n",
      "\n",
      "    accuracy                           0.65       214\n",
      "   macro avg       0.59      0.65      0.57       214\n",
      "weighted avg       0.79      0.65      0.69       214\n",
      "\n",
      "[[115  62]\n",
      " [ 13  24]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "history = nn.fit(X_under_train, y_under_train, epochs=epochs, verbose=0, validation_data=(x_val, y_val))\n",
    "\n",
    "y_pred_train = nn.predict(X_under_train)\n",
    "y_pred_train = y_pred_train > 0.5\n",
    "y_pred = nn.predict(x_val)\n",
    "y_pred = y_pred > 0.5\n",
    "\n",
    "# show_metrics(history)\n",
    "print(\"Train\")\n",
    "print(classification_report(y_under_train, y_pred_train, zero_division=0))\n",
    "print(\"Test\")\n",
    "print(classification_report(y_val, y_pred, zero_division=0))\n",
    "\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGqt7Kc7BCJ-"
   },
   "source": [
    "#### EditedNearestNeighbours\n",
    "Con esta técnicaa se eliminan registros haciendo uso de k-vecinos cercanos, a partir de la que se eliminan registros cercanos a la frontera de decisión para distinguir entre una clase y otra. Debido a que en la frontera de decisión no existen muchos registros de la clase 0 solo se eliminan unos pocos quedando las clases muy desequilibradas por lo que el modelo pondera la clase 0 por encima de la clase 1 quedando unos f1 scores muy altos para la clase 0 pero nulos para la clase 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1651674890829,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "EBgW7tymBB0R",
    "outputId": "458c2b37-fa38-4d02-9a29-a5707253c95f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 512, 1.0: 145})\n"
     ]
    }
   ],
   "source": [
    "enn = EditedNearestNeighbours()\n",
    "X_under_train, y_under_train = enn.fit_resample(x_train, y_train)\n",
    "print(Counter(y_under_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10794,
     "status": "ok",
     "timestamp": 1651674901607,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "dqhOZTUxCXzH",
    "outputId": "4e7ea56c-7ede-4641-e90b-19b47d846731"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      1.00      0.88       512\n",
      "         1.0       0.00      0.00      0.00       145\n",
      "\n",
      "    accuracy                           0.78       657\n",
      "   macro avg       0.39      0.50      0.44       657\n",
      "weighted avg       0.61      0.78      0.68       657\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      1.00      0.91       177\n",
      "         1.0       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.83       214\n",
      "   macro avg       0.41      0.50      0.45       214\n",
      "weighted avg       0.68      0.83      0.75       214\n",
      "\n",
      "[[177   0]\n",
      " [ 37   0]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "history = nn.fit(X_under_train, y_under_train, epochs=epochs, verbose=0, validation_data=(x_val, y_val))\n",
    "\n",
    "y_pred_train = nn.predict(X_under_train)\n",
    "y_pred_train = y_pred_train > 0.5\n",
    "y_pred = nn.predict(x_val)\n",
    "y_pred = y_pred > 0.5\n",
    "\n",
    "# show_metrics(history)\n",
    "print(\"Train\")\n",
    "print(classification_report(y_under_train, y_pred_train, zero_division=0))\n",
    "print(\"Test\")\n",
    "print(classification_report(y_val, y_pred, zero_division=0))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPJQ1CBFByj5"
   },
   "source": [
    "#### TomekLinks\n",
    "Haciendo uso de esta técnica se eliminan los registos de la clase numerosa haciendo uso de los enlaces de Tomek los cuales son enlaces entre clases proximas. Debido a que las clases no están muy próximas apenas se eliminan 5 registros de la clase 0 quedando las clases muy desequilibradas por lo que el modelo pondera la clase 0 por encima de la clase 1 quedando unos f1 scores muy altos para la clase 0 pero nulos para la clase 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1651674901607,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "VdvRN5igB1T8",
    "outputId": "f235c662-006b-4a7b-a60e-3ad5b8163a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 702, 1.0: 145})\n"
     ]
    }
   ],
   "source": [
    "tl = TomekLinks()\n",
    "X_under_train, y_under_train = tl.fit_resample(x_train, y_train)\n",
    "print(Counter(y_under_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20325,
     "status": "ok",
     "timestamp": 1651674921929,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "LMLvM57tCfsj",
    "outputId": "c8423780-df8f-46e9-e43e-78aa6e3e82ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      1.00      0.91       702\n",
      "         1.0       0.00      0.00      0.00       145\n",
      "\n",
      "    accuracy                           0.83       847\n",
      "   macro avg       0.41      0.50      0.45       847\n",
      "weighted avg       0.69      0.83      0.75       847\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      1.00      0.91       177\n",
      "         1.0       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.83       214\n",
      "   macro avg       0.41      0.50      0.45       214\n",
      "weighted avg       0.68      0.83      0.75       214\n",
      "\n",
      "[[177   0]\n",
      " [ 37   0]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "history = nn.fit(X_under_train, y_under_train, epochs=epochs, verbose=0, validation_data=(x_val, y_val))\n",
    "\n",
    "y_pred_train = nn.predict(X_under_train)\n",
    "y_pred_train = y_pred_train > 0.5\n",
    "y_pred = nn.predict(x_val)\n",
    "y_pred = y_pred > 0.5\n",
    "\n",
    "# show_metrics(history)\n",
    "print(\"Train\")\n",
    "print(classification_report(y_under_train, y_pred_train, zero_division=0))\n",
    "print(\"Test\")\n",
    "print(classification_report(y_val, y_pred, zero_division=0))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RQMdB-WCDJU"
   },
   "source": [
    "#### RandomOverSampler\n",
    "Esta técnia para la clase minoritaria aumenta el número de registros hasta quedarse con el mismo número de registros que la clase mayoritaria. Los registros los aumenta escogiendo registros repetidos de la clase minoritaria de forma aleatoria. Debido a que el numero de registros de las clases se encuentra equilibrado obtiene buenos f1 scores para ambas clases en entrenamiento aunque algo peores en test como ocurria con Random Under Sampler debido a que aunque ahora tiene más registros de la clase 1 para entrenarse y puede ponderar de forma equilibrada ambas clases, no tiene suficientes registros de la clase 1 que le permita generalizar bien ya que es poco el conocimiento que adquiere de ellos ya que muchos están repetidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1651674921929,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "MR_N0WmEiOwR",
    "outputId": "2c1a3c7b-89c9-4b1f-ad7d-ec26f4eee335"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 707, 1.0: 707})\n"
     ]
    }
   ],
   "source": [
    "oversample = RandomOverSampler()\n",
    "X_over_train, y_over_train = oversample.fit_resample(x_train, y_train)\n",
    "print(Counter(y_over_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "executionInfo": {
     "elapsed": 13152,
     "status": "error",
     "timestamp": 1651674935079,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "Y1__o4r8CTK6",
    "outputId": "cb65bb01-f845-4265-e841-4146024072af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.51      0.55       707\n",
      "         1.0       0.58      0.67      0.62       707\n",
      "\n",
      "    accuracy                           0.59      1414\n",
      "   macro avg       0.59      0.59      0.59      1414\n",
      "weighted avg       0.59      0.59      0.59      1414\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.45      0.60       177\n",
      "         1.0       0.22      0.73      0.34        37\n",
      "\n",
      "    accuracy                           0.50       214\n",
      "   macro avg       0.55      0.59      0.47       214\n",
      "weighted avg       0.77      0.50      0.55       214\n",
      "\n",
      "[[80 97]\n",
      " [10 27]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "history = nn.fit(X_over_train, y_over_train, epochs=epochs, verbose=0, validation_data=(x_val, y_val))\n",
    "\n",
    "y_pred_train = nn.predict(X_over_train)\n",
    "y_pred_train = y_pred_train > 0.5\n",
    "y_pred = nn.predict(x_val)\n",
    "y_pred = y_pred > 0.5\n",
    "\n",
    "# show_metrics(history)\n",
    "print(\"Train\")\n",
    "print(classification_report(y_over_train, y_pred_train, zero_division=0))\n",
    "print(\"Test\")\n",
    "print(classification_report(y_val, y_pred, zero_division=0))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olAub6eqCimx"
   },
   "source": [
    "#### SMOTE\n",
    "Esta técnicas generan muestras de la clase minoritaria a partir de la interpolación dejandolas equilibradas y consiguiendo buenos resultados en entrenamiento aunque nuevamente algo peores en test por lo que se ha explicado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1651674935074,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "qsanL5kICHqz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 707, 1.0: 707})\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE()\n",
    "X_over_train, y_over_train = sm.fit_resample(x_train, y_train)\n",
    "print(Counter(y_over_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1651674935075,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "ATfGBRFBCUPw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.74      0.69       707\n",
      "         1.0       0.69      0.58      0.63       707\n",
      "\n",
      "    accuracy                           0.66      1414\n",
      "   macro avg       0.66      0.66      0.66      1414\n",
      "weighted avg       0.66      0.66      0.66      1414\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.66      0.76       177\n",
      "         1.0       0.27      0.59      0.37        37\n",
      "\n",
      "    accuracy                           0.65       214\n",
      "   macro avg       0.58      0.63      0.56       214\n",
      "weighted avg       0.78      0.65      0.69       214\n",
      "\n",
      "[[117  60]\n",
      " [ 15  22]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "history = nn.fit(X_over_train, y_over_train, epochs=epochs, verbose=0, validation_data=(x_val, y_val))\n",
    "\n",
    "y_pred_train = nn.predict(X_over_train)\n",
    "y_pred_train = y_pred_train > 0.5\n",
    "y_pred = nn.predict(x_val)\n",
    "y_pred = y_pred > 0.5\n",
    "\n",
    "# show_metrics(history)\n",
    "print(\"Train\")\n",
    "print(classification_report(y_over_train, y_pred_train, zero_division=0))\n",
    "print(\"Test\")\n",
    "print(classification_report(y_val, y_pred, zero_division=0))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNSAQApYCj_z"
   },
   "source": [
    "#### ADASYN\n",
    "Esta técnica genera muestras de la clase minoritaria a partir de la interpolación. A diferencia de Smote, Adasyn se centra en generar muestras, que se encuentran junto a las muestras originales que se clasifican erróneamente, utilizando una clasificación k-Vecinos más cercanos. Por su parte el algoritmo SMOTE no hace ninguna distinción entre muestras para ser clasificadas utilizando la regla de vecinos más cercanos.\n",
    "\n",
    "Nuevamente obtiene resultados similares a Somte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1651674935075,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "GVhT0WIrCH-e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 707, 1.0: 692})\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN()\n",
    "X_over_train, y_over_train = ada.fit_resample(x_train, y_train)\n",
    "print(Counter(y_over_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1651674935076,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "7J2rLncm2oHc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.79      0.68       707\n",
      "         1.0       0.68      0.46      0.55       692\n",
      "\n",
      "    accuracy                           0.63      1399\n",
      "   macro avg       0.64      0.62      0.62      1399\n",
      "weighted avg       0.64      0.63      0.62      1399\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.69      0.78       177\n",
      "         1.0       0.29      0.59      0.39        37\n",
      "\n",
      "    accuracy                           0.67       214\n",
      "   macro avg       0.59      0.64      0.58       214\n",
      "weighted avg       0.79      0.67      0.71       214\n",
      "\n",
      "[[122  55]\n",
      " [ 15  22]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "history = nn.fit(X_over_train, y_over_train, epochs=epochs, verbose=0, validation_data=(x_val, y_val))\n",
    "\n",
    "y_pred_train = nn.predict(X_over_train)\n",
    "y_pred_train = y_pred_train > 0.5\n",
    "y_pred = nn.predict(x_val)\n",
    "y_pred = y_pred > 0.5\n",
    "\n",
    "# show_metrics(history)\n",
    "print(\"Train\")\n",
    "print(classification_report(y_over_train, y_pred_train, zero_division=0))\n",
    "print(\"Test\")\n",
    "print(classification_report(y_val, y_pred, zero_division=0))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Las técnicas de Tome Links y edited nearest neighbours no se han comportado bien ya que no han eliminado suficientes registros de la clase mayoritaria ya que no cumplían muchas registros las condiciones de los dos algoritmos anteriores ponderando el modelo la clase 0 por encima de la 1 y obteniendose resultados malos para la clase 1. Sin embargo a partir de las otras técnicas se ha conseguido un equilibrio de registros entre clases por lo que el modelo no ha ponderado una clase sobre la otra consiguiendo buenos resultados en entrenamiento y, resultados decentes aunque peores en test debido a que haciendo uso de las técnicas de undersampling no se tenína suficientes registros de la clase 1 para modelas y entenar un modelo con gran capacidad de generalizacion en test y debido a que las técnicas de oversampling, los registros apenas han aportado nuevo conocimiento al modelo de la clase 1 por lo que tampoco ha sabido generalizar en test de la mejor forma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUMBdOam2oHd"
   },
   "source": [
    "### Uso de class_weight pero con paquete que nos proporciona\n",
    "Otra forma de conseguir un equilibrio de ponderación entre clases es computar pesos para cada clase, con resultados similares a las técnicas anteriores donde se conseguia un equilibrio de registros entre clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1651674935076,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "CJfmolAdkGDY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.6025459688826026, 1: 2.9379310344827587}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1651674935076,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "j4hMiyuSkQgK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.78      0.83       707\n",
      "         1.0       0.34      0.57      0.43       145\n",
      "\n",
      "    accuracy                           0.74       852\n",
      "   macro avg       0.62      0.67      0.63       852\n",
      "weighted avg       0.80      0.74      0.77       852\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.68      0.77       177\n",
      "         1.0       0.28      0.59      0.38        37\n",
      "\n",
      "    accuracy                           0.67       214\n",
      "   macro avg       0.59      0.64      0.58       214\n",
      "weighted avg       0.78      0.67      0.71       214\n",
      "\n",
      "[[121  56]\n",
      " [ 15  22]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "history = nn.fit(x_train, y_train, epochs=epochs, verbose=0, class_weight=class_weights, validation_data=(x_val, y_val))\n",
    "\n",
    "y_pred_train = nn.predict(x_train)\n",
    "y_pred_train = y_pred_train > 0.5\n",
    "y_pred = nn.predict(x_val)\n",
    "y_pred = y_pred > 0.5\n",
    "\n",
    "# show_metrics(history)\n",
    "print(\"Train\")\n",
    "print(classification_report(y_train, y_pred_train, zero_division=0))\n",
    "print(\"Test\")\n",
    "print(classification_report(y_val, y_pred, zero_division=0))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Nuevamente gracias a la ponderación se consiguen resultados decentes y que no pondere una clase sobre la otra pero la red tiene poca capacidad de generalizacion para la clase 1 debido a que le falta más conocimiento sobre esta para generalizar mejor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeHlBkW9oDdQ"
   },
   "source": [
    "### Aplicar todas las ténicas a la vez.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orwBLXgnCn78"
   },
   "source": [
    "#### RandomUnderSampler + RandomOverSampler\n",
    "A partir de esta combiación de téncias se reducen registros de la clase mayoritaria la 0, eliminando registros de manera aleatoria y creamos registros para la clase minoritaria y se computan pesos para que no pondere la clase 0 la cual seguiría teniendo más registros que la clase 1, pero como se ha estado explicando la ponderación solo es uno de los problemas por lo que obtiene resultados decentes pero no muy precisos para la clase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1651675207043,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "OhLi7HIpqF0u",
    "outputId": "2c1f771f-d71b-4ee2-9a04-73d78de80275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 707, 1.0: 145})\n",
      "Counter({0.0: 707, 1.0: 282})\n",
      "Counter({0.0: 564, 1.0: 282})\n",
      "{0: 0.75, 1: 1.5}\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy=0.4)\n",
    "X_over_train, y_over_train = oversample.fit_resample(x_train, y_train)\n",
    "print(Counter(y_over_train))\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.5)\n",
    "X_ajust_train, y_ajust_train = undersample.fit_resample(X_over_train, y_over_train)\n",
    "print(Counter(y_ajust_train))\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_ajust_train), y=y_ajust_train)\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13139,
     "status": "ok",
     "timestamp": 1651675221205,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "6wsZ4r5Oul7o",
    "outputId": "d457f51b-13b1-486a-e939-305bd1d2b824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.77      0.77       564\n",
      "         1.0       0.55      0.56      0.55       282\n",
      "\n",
      "    accuracy                           0.70       846\n",
      "   macro avg       0.66      0.66      0.66       846\n",
      "weighted avg       0.70      0.70      0.70       846\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.68      0.77       177\n",
      "         1.0       0.28      0.59      0.38        37\n",
      "\n",
      "    accuracy                           0.66       214\n",
      "   macro avg       0.58      0.64      0.57       214\n",
      "weighted avg       0.78      0.66      0.70       214\n",
      "\n",
      "[[120  57]\n",
      " [ 15  22]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "history = nn.fit(X_ajust_train, y_ajust_train, epochs=epochs, verbose=0, class_weight=class_weights, validation_data=(x_val, y_val))\n",
    "\n",
    "y_pred_train = nn.predict(X_ajust_train)\n",
    "y_pred_train = y_pred_train > 0.5\n",
    "y_pred = nn.predict(x_val)\n",
    "y_pred = y_pred > 0.5\n",
    "\n",
    "# show_metrics(history)\n",
    "print(\"Train\")\n",
    "print(classification_report(y_ajust_train, y_pred_train, zero_division=0))\n",
    "print(\"Test\")\n",
    "print(classification_report(y_val, y_pred, zero_division=0))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fCTUQAbCtI3"
   },
   "source": [
    "#### SMOTE + ENN\n",
    "Estas técnicas se combinan con el fin de reducir el numero de muestras de la clase mayoritaria haciendo uso de EditedNearestNeighbours eliminando los registros de esta clase que se encuentran en la frontera de decisión, y conseguir más muestras de la clase minoritaria con SMOTE como a partir de interpolación consiguiendo cierto equilibrio entre las clases 0 y 1 obteniendo resultados similares al anterior caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1651675235504,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "GiQvtEFhDOCr",
    "outputId": "c0128861-4090-4519-e01a-89681cd1c073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 431, 1.0: 313})\n"
     ]
    }
   ],
   "source": [
    "smoteen = SMOTEENN()\n",
    "X_ajust_train, y_ajust_train = smoteen.fit_resample(x_train, y_train)\n",
    "print(Counter(y_ajust_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17331,
     "status": "ok",
     "timestamp": 1651675253760,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "RMOU0OBefmfo",
    "outputId": "6489cd24-06ad-4f10-896e-99a216d5d766"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.92      0.84       431\n",
      "         1.0       0.86      0.64      0.73       313\n",
      "\n",
      "    accuracy                           0.80       744\n",
      "   macro avg       0.82      0.78      0.79       744\n",
      "weighted avg       0.81      0.80      0.80       744\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.73      0.80       177\n",
      "         1.0       0.29      0.54      0.38        37\n",
      "\n",
      "    accuracy                           0.70       214\n",
      "   macro avg       0.59      0.63      0.59       214\n",
      "weighted avg       0.78      0.70      0.73       214\n",
      "\n",
      "[[129  48]\n",
      " [ 17  20]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "history = nn.fit(X_ajust_train, y_ajust_train, epochs=epochs, verbose=0, validation_data=(x_val, y_val))\n",
    "\n",
    "y_pred_train = nn.predict(X_ajust_train)\n",
    "y_pred_train = y_pred_train > 0.5\n",
    "y_pred = nn.predict(x_val)\n",
    "y_pred = y_pred > 0.5\n",
    "\n",
    "# show_metrics(history)\n",
    "print(\"Train\")\n",
    "print(classification_report(y_ajust_train, y_pred_train, zero_division=0))\n",
    "print(\"Test\")\n",
    "print(classification_report(y_val, y_pred, zero_division=0))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISdM_KH_DApy"
   },
   "source": [
    "#### SMOTE + Tomek\n",
    "Estas técnicas se combinan con el fin de reducir el numero de muestras de la clase mayoritaria haciendo uso de Tomek eliminando los registros de esta clase que se encuentran con enlaces Tomek con un valor de distancia muy pequeño, y conseguir más muestras de la clase minoritaria con SMOTE como a partir de interpolación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1651675098163,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "wIWEAMG-EFsR",
    "outputId": "7ecfd596-b29d-455a-e1cc-f3744e3445dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 705, 1.0: 705})\n"
     ]
    }
   ],
   "source": [
    "smtomek = SMOTETomek()\n",
    "X_ajust_train, y_ajust_train = smtomek.fit_resample(x_train, y_train)\n",
    "print(Counter(y_ajust_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20609,
     "status": "ok",
     "timestamp": 1651675118749,
     "user": {
      "displayName": "Zhi jie Qian",
      "userId": "17587581155014799590"
     },
     "user_tz": -120
    },
    "id": "ZgwSbTteDOhN",
    "outputId": "cfcc1836-0e9e-4841-8b90-e2464ef12f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.76      0.71       705\n",
      "         1.0       0.72      0.60      0.65       705\n",
      "\n",
      "    accuracy                           0.68      1410\n",
      "   macro avg       0.69      0.68      0.68      1410\n",
      "weighted avg       0.69      0.68      0.68      1410\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.65      0.75       177\n",
      "         1.0       0.28      0.65      0.39        37\n",
      "\n",
      "    accuracy                           0.65       214\n",
      "   macro avg       0.59      0.65      0.57       214\n",
      "weighted avg       0.79      0.65      0.69       214\n",
      "\n",
      "[[115  62]\n",
      " [ 13  24]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "history = nn.fit(X_ajust_train, y_ajust_train, epochs=epochs, verbose=0, validation_data=(x_val, y_val))\n",
    "\n",
    "y_pred_train = nn.predict(X_ajust_train)\n",
    "y_pred_train = y_pred_train > 0.5\n",
    "y_pred = nn.predict(x_val)\n",
    "y_pred = y_pred > 0.5\n",
    "\n",
    "# show_metrics(history)\n",
    "print(\"Train\")\n",
    "print(classification_report(y_ajust_train, y_pred_train, zero_division=0))\n",
    "print(\"Test\")\n",
    "print(classification_report(y_val, y_pred, zero_division=0))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "La combinación de técnicas de reducción para la clase mayoritaria y ampliación de la clase minoritaria consiguen que no se pondere una clase sobre la otra y obtiene buenos resultados pero no termina de generalizar con precisión para la clase 1 debido a que faltan más registros para esta clase que aporten conocimiento a la red para distinguirlos de los de la otra clase.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neuro_P3_normal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
